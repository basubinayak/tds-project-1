{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 419 entries, 0 to 418\n",
      "Data columns (total 11 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   login         419 non-null    object\n",
      " 1   name          416 non-null    object\n",
      " 2   company       258 non-null    object\n",
      " 3   location      419 non-null    object\n",
      " 4   email         197 non-null    object\n",
      " 5   hireable      419 non-null    object\n",
      " 6   bio           336 non-null    object\n",
      " 7   public_repos  419 non-null    int64 \n",
      " 8   followers     419 non-null    int64 \n",
      " 9   following     419 non-null    int64 \n",
      " 10  created_at    419 non-null    object\n",
      "dtypes: int64(3), object(8)\n",
      "memory usage: 36.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# loading the users.csv data \n",
    "users_df = pd.read_csv('users.csv')\n",
    "users_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['name', 'company', 'email', 'bio']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# columns which have null values\n",
    "users_df.columns[users_df.isnull().any()].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 Chennai GitHub users by follower count:\n",
      "Premalatha-success: 2035 followers\n",
      "anitaa1990: 1947 followers\n",
      "codewithMUHILAN: 1831 followers\n",
      "sygops: 1815 followers\n",
      "Spikeysanju: 1296 followers\n",
      "\n",
      "Comma-separated list of logins:\n",
      "Premalatha-success,anitaa1990,codewithMUHILAN,sygops,Spikeysanju\n"
     ]
    }
   ],
   "source": [
    "# Who are the top 5 users in Chennai with the highest number of followers? List their login in order, comma-separated.\n",
    "\n",
    "# Sort users by followers count in descending order\n",
    "top_users = users_df.sort_values('followers', ascending=False).head(5)\n",
    "\n",
    "# Print results\n",
    "print(\"\\nTop 5 Chennai GitHub users by follower count:\")\n",
    "# iterrows() is a pandas method that allows you to iterate over the rows of a DataFrame as pairs of index and row data. It’s commonly used when you want to loop through each row and access or process data row by row. \n",
    "for index, user in top_users.iterrows():\n",
    "    print(f\"{user['login']}: {user['followers']} followers\")\n",
    "\n",
    "print(\"\\nComma-separated list of logins:\")\n",
    "print(\",\".join(top_users['login'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Earliest 5 GitHub users from Chennai:\n",
      "cnu: 2008-03-27\n",
      "railsfactory: 2008-04-06\n",
      "sudhirj: 2008-08-23\n",
      "ravijaya: 2008-12-05\n",
      "badri: 2008-12-21\n",
      "\n",
      "Comma-separated list of logins (in chronological order):\n",
      "cnu,railsfactory,sudhirj,ravijaya,badri\n"
     ]
    }
   ],
   "source": [
    "# Who are the 5 earliest registered GitHub users in Chennai? List their login in ascending order of created_at, comma-separated.\n",
    "\n",
    "# Convert created_at to datetime\n",
    "users_df['created_at'] = pd.to_datetime(users_df['created_at'])\n",
    "\n",
    "# Sort by created_at in ascending order and get top 5\n",
    "earliest_users = users_df.sort_values('created_at').head(5)\n",
    "\n",
    "# Print results\n",
    "print(\"\\nEarliest 5 GitHub users from Chennai:\")\n",
    "for index, user in earliest_users.iterrows():\n",
    "    print(f\"{user['login']}: {user['created_at'].strftime('%Y-%m-%d')}\")\n",
    "\n",
    "print(\"\\nComma-separated list of logins (in chronological order):\")\n",
    "print(\",\".join(earliest_users['login'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26334 entries, 0 to 26333\n",
      "Data columns (total 9 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   login             26334 non-null  object\n",
      " 1   full_name         26334 non-null  object\n",
      " 2   created_at        26334 non-null  object\n",
      " 3   stargazers_count  26334 non-null  int64 \n",
      " 4   watchers_count    26334 non-null  int64 \n",
      " 5   language          18700 non-null  object\n",
      " 6   has_projects      26334 non-null  bool  \n",
      " 7   has_wiki          26334 non-null  bool  \n",
      " 8   license_name      9875 non-null   object\n",
      "dtypes: bool(2), int64(2), object(5)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# Read the data\n",
    "repos_df = pd.read_csv('repositories.csv')\n",
    "\n",
    "repos_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['language', 'license_name']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# which columns have null values?\n",
    "repos_df.columns[repos_df.isna().any()].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'apache-2.0', 'mit', 'gpl-2.0', 'unlicense', 'other',\n",
       "       'upl-1.0', 'gpl-3.0', 'mpl-2.0', 'bsd-3-clause', 'agpl-3.0',\n",
       "       'cc0-1.0', 'lgpl-2.1', 'ms-pl', 'isc', 'bsd-2-clause', 'cc-by-4.0',\n",
       "       'cc-by-sa-4.0', 'lgpl-3.0', 'wtfpl', 'epl-2.0', 'epl-1.0', 'mit-0',\n",
       "       'bsl-1.0', '0bsd', 'ofl-1.1', 'ncsa', 'odbl-1.0', 'zlib',\n",
       "       'artistic-2.0', 'osl-3.0'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repos_df['license_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Top 3 Popular Licenses ===\n",
      "Top licenses: mit,apache-2.0,other\n"
     ]
    }
   ],
   "source": [
    "#What are the 3 most popular license among these users? Ignore missing licenses. List the license_name in order, comma-separated.\n",
    "\n",
    "# Read the data\n",
    "repos_df = pd.read_csv('repositories.csv')\n",
    "\n",
    "# 3. Most popular licenses\n",
    "print(\"\\n=== Top 3 Popular Licenses ===\")\n",
    "license_counts = repos_df[repos_df['license_name'].notna()]['license_name'].value_counts()\n",
    "print(\"Top licenses:\", \",\".join(license_counts.head(3).index.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AI CONSULTANT/DATA SCIENTIST/TRAINER/FREELANCER/SPEAKER/THESIS SUPERVISOR/MENTOR/YOUTUBER',\n",
       " nan,\n",
       " 'THISUXHQ',\n",
       " 'NIELSENIQ',\n",
       " 'WEBTODAY BUSIENESS',\n",
       " 'MANDO',\n",
       " 'DHL IT SERVICES',\n",
       " 'JGNACADEMY',\n",
       " 'ZOHO',\n",
       " 'INFORMATICA',\n",
       " 'TESTLEAF',\n",
       " 'CYBERDUDENETWORKS',\n",
       " 'LETCODE',\n",
       " 'TRANSAK.COM',\n",
       " 'TARIDES AND IIT MADRAS',\n",
       " 'UB TECHNOLOGY INNOVATIONS',\n",
       " 'PROGRAMMERS-GATEWAY',\n",
       " 'BIZNESSFORCE SOFTWARE SOLUTIONS PTE LTD.',\n",
       " 'SELF EMPLOYED',\n",
       " 'ARROWOS @PIXELOS-AOSP',\n",
       " 'ZUORA',\n",
       " 'PAYILAGAM',\n",
       " 'DUN & BRADSTREET',\n",
       " 'SAAMA.COM',\n",
       " 'CAPGEMINI',\n",
       " 'OLACABS',\n",
       " 'ZOHO CORPORATION',\n",
       " 'CHARGEBEE (@CHARGEBEE)',\n",
       " 'CRED-CLUB, @NOKIA, @DSCVITC',\n",
       " 'THINKSPERT',\n",
       " 'UNIVERSUM',\n",
       " 'CLARIFAI',\n",
       " 'QUELIT',\n",
       " 'VELLORE INSTITUTE OF TECHNOLOGY',\n",
       " 'NFNLABS',\n",
       " 'JUSPAY TECHNOLOGIES PVT LTD',\n",
       " 'DELOITTE',\n",
       " 'MADRAS INSTITUTE OF TECHNOLOGY',\n",
       " 'DSCVITC @ENACTUSVITC @0XGIZMOLAB @SARVAMTRE',\n",
       " 'THEECODE TECHNOLOGIES',\n",
       " 'HTC INDIA',\n",
       " 'THOUGHTWORKS INC.',\n",
       " 'CODELANCE-DEVS, @SUNDAR-CLINIC',\n",
       " 'SAAMARESEARCH',\n",
       " 'RAJALAKSHMI INSTITUTE OF TECHNOLOGY',\n",
       " 'KAAR TECHNOLOGIES',\n",
       " 'EX-VIT, MSP, HASURA, MR.COOPER',\n",
       " 'SKIT-AI',\n",
       " 'THOUGHTWORKS',\n",
       " 'MILA – QUEBEC AI INSTITUTE (@MILA-IQIA) & UNIVERSITÉ DE MONTRÉAL',\n",
       " 'FEATHERS-STUDIO',\n",
       " 'ATTUNE INC',\n",
       " 'AVALARA',\n",
       " 'SKCRIPT',\n",
       " 'ZILOGIC SYSTEMS',\n",
       " 'NEXTTECHLAB',\n",
       " 'CARLRESEARCH',\n",
       " 'IIT MADRAS',\n",
       " 'FTC SOLAR',\n",
       " 'INDIAN INSTITUTE OF TECHNOLOGY MADRAS',\n",
       " 'GRYFFINDORS',\n",
       " 'CARNEGIE MELLON UNIVERSITY',\n",
       " 'NAETHRA TECHNOLOGIES PVT. LTD.',\n",
       " 'TCS',\n",
       " 'GENOME LIFE SCIENCES',\n",
       " 'JAVA, KOTLIN, AGILE COMMUNITY GUY',\n",
       " 'CHENNAI INSTITUTE OF TECHNOLOGY',\n",
       " 'UNICORN DATA SCIENCE PRACTITIONER',\n",
       " 'ELECTRONICS CORPORATION OF INDIA LTD.',\n",
       " 'FOUNDER AT DNYX',\n",
       " 'SYNCHRONY',\n",
       " 'EPIC-PROGRAMMER-OFFICIAL',\n",
       " 'APPLE',\n",
       " 'NONCEBLOX',\n",
       " 'GUVI GEEK PVT.LMT',\n",
       " 'E2 INFOSYSTEMS PVT LTD',\n",
       " 'ORACLE @SPIDERNITT',\n",
       " 'PUTHIR',\n",
       " 'DATAMOO-AI',\n",
       " 'BRINE SOFTWARES SOLUTION PVT LTD.',\n",
       " 'TIMELESS',\n",
       " 'LUMALABS',\n",
       " 'TRIMBLE INC',\n",
       " 'LOGIC SOFT PVT. LTD.',\n",
       " 'DOODLEBLUE INNOVATIONS',\n",
       " 'NIMBLEBOXAI',\n",
       " 'TEAMRUDRA @ALEXASRM @HACKTHEBOX-SRMIST',\n",
       " 'QUEST LABS',\n",
       " 'INDIAN INSTITUTE OF TECHNOLOGY, MANDI',\n",
       " 'IMAGINEA TECHNOLOGIES',\n",
       " 'MOTORQ',\n",
       " 'CRED',\n",
       " 'KYRO',\n",
       " 'ANDROIDSOURCES.COM',\n",
       " 'NESIN TECHNOLOGIES LLP',\n",
       " 'INCORESEMI',\n",
       " 'GOOGLE',\n",
       " 'NIMBLEBOXAI @TUNEHQ',\n",
       " 'SWE @MICROSOFT, MENTOR @MLH',\n",
       " 'L&T EDUTECH',\n",
       " 'ZILKER TECHNOLGIES',\n",
       " 'SRM INSTITUTE OF SCIENCE AND TECHNOLOGY',\n",
       " 'HEADOUT',\n",
       " 'DATA SCIENTIST @ IOPEX TECHNOLOGIES',\n",
       " 'SRM INSTITUTE OF SCIENCE AND TECHNOLOGY, RAMAPURAM',\n",
       " 'COGNIZANCE',\n",
       " 'HTTPS://ILOVEDOTNET.ORG',\n",
       " 'KLA+',\n",
       " 'CHARING CROSS CAPITAL',\n",
       " 'DUNDER-OSS',\n",
       " 'TIMELESSCO',\n",
       " 'FRESHWORKS',\n",
       " 'SPRITLESOFTWARE',\n",
       " 'HID GLOBAL',\n",
       " 'DURASOFT',\n",
       " 'KLA-TENCOR',\n",
       " 'SURFBOARD PAYMENTS',\n",
       " 'SRMIST KTR',\n",
       " 'BIO-MIMETICS LAB, INDIAN INSTITUTE OF TECHNOLOGY MADRAS',\n",
       " 'CITI',\n",
       " 'AGARWALCONSULTING.IO',\n",
       " 'CODING WITH NITHISH',\n",
       " 'DINESHDINZ',\n",
       " 'KINGS ENGINEERING COLLEGE',\n",
       " 'GREAT LEARNING',\n",
       " 'PAYPAL',\n",
       " 'RAILSFACTORY',\n",
       " 'ACCENTURE',\n",
       " 'CHADURA TECH',\n",
       " 'FIDISYS',\n",
       " 'PICCOSOFT SOFTWARE LABS INDIA PVT LTD',\n",
       " 'STARTUP ANDROIDMANIFESTER',\n",
       " 'TERRIFIC MINDS',\n",
       " 'MUONIUM',\n",
       " 'STRATFORGE',\n",
       " 'TIMECAMPUS @BURDENOFF @CONVINTAI',\n",
       " 'THOUGHTWORKSINC',\n",
       " 'ELEVATEDSIGNALS',\n",
       " 'AMAZON',\n",
       " 'HACKALIST, @BINPY, @HACKINOUT',\n",
       " 'BEEZ INNOVATION LABS PVT. LTD',\n",
       " 'BIG-DATA-EXAMINER',\n",
       " 'YNOS-VENTURE-ENGINE',\n",
       " 'IIITDM KANCHEEPURAM',\n",
       " 'SWIFTSKU',\n",
       " 'TARIDES',\n",
       " 'DELTA',\n",
       " 'SRMIST',\n",
       " 'SOFTWARE DEVELOPER',\n",
       " 'COMCAST',\n",
       " 'BRISKINFOSEC TECHNOLOGY AND CONSULTING PVT LTD',\n",
       " 'GOJEK',\n",
       " 'TARKALABS',\n",
       " 'COURSEPANEL',\n",
       " 'AT&T',\n",
       " 'R.M.K ENGINEERING COLLEGE',\n",
       " 'RAMAJAYAM AND ASSOCIATES',\n",
       " 'AI STUDENT AT RMKCET',\n",
       " 'NOT AVAILABLE FOR HIRE',\n",
       " 'EX-INFOSYS',\n",
       " 'SEVEN (7) STACKS CONSULTANCY LLP',\n",
       " 'DELTA FORCE',\n",
       " 'HUMBLX-PROD',\n",
       " 'INDEPENDENT FREELANCER',\n",
       " 'ROOTCAP LINUX',\n",
       " 'MASAI SCHOOL',\n",
       " 'VELS UNIVERSITY',\n",
       " 'NEARCAST',\n",
       " 'ASSOCIATE MACHINE LEARNING ENGINEER @CONTENTSTACK',\n",
       " 'TRUELAYER',\n",
       " 'LITEKITE',\n",
       " 'ATOMICITS',\n",
       " 'NETHERMINDETH @DAO-COMMUNITY-VITC @0XHASHSTACK  @GOLDDUST-PROTOCOL @BEATSPIRE @MATICNETWORK @PLACEXP @EDMYN',\n",
       " 'PANDOCORP',\n",
       " 'SEEKING INTERNSHIPS ON DATA SCIENCE',\n",
       " 'CHENNAI INSTITUTE OF TECHNOLOGY (CIT) CHENNAI',\n",
       " 'SAHAJ AI',\n",
       " 'CHENNAI',\n",
       " 'SENIOR PRODUCT DEVELOPER AT LUMEL',\n",
       " 'DEVOPS - PLATFORM ENGINEERING',\n",
       " 'VELLORE INSTITUTE OF TECHNOLOGY (VIT), CHENNAI',\n",
       " 'COGNIZANT TECHNOLOGY SOLUTIONS',\n",
       " 'KTERN.AI',\n",
       " 'CONCORD TECHNOLOGIES',\n",
       " 'ROCKETLANE',\n",
       " '#XAMARINMONKEYS',\n",
       " 'STUDENT AT SIST',\n",
       " 'MADRAS INSTITUTE OF TECHNOLOGY , CHENNAI',\n",
       " 'IEEE-VIT',\n",
       " 'THEGEEKMACHINE',\n",
       " 'POSTMAN',\n",
       " 'IIT MADRAS ONLINE DEGREE',\n",
       " 'COINDCX',\n",
       " 'THE SPARKS FOUNDATION, SINGAPORE',\n",
       " 'BRAINSIGHTAI',\n",
       " 'ALCHEMILLA PRIVATE LIMITED',\n",
       " 'MASAI SCHOOL- BANGALORE',\n",
       " 'DOGE-CAPITAL @CODECHEF-SRMRMP @WEB3-BHARAT',\n",
       " 'HAPPYFOXINC',\n",
       " 'SATHYABAMA INSTITUTE OF SCIENCE AND TECHNOLOGY',\n",
       " 'TYPESENSE',\n",
       " 'WORKATO',\n",
       " 'ADV INDIAN CODER',\n",
       " 'ORACLE',\n",
       " 'ASSISTANT PROFESSOR | RESEARCHER | FREELANCER',\n",
       " 'DOGE-CAPITAL',\n",
       " 'TELIVER',\n",
       " 'INCORE SEMICONDUCTORS PVT. LTD',\n",
       " 'PINACA-LABS',\n",
       " 'ZOHO CORP',\n",
       " 'MCCARTHY LAB, NEXTECH']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_df['company'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Most Common Company ===\n",
      "Most common company: ZOHO\n"
     ]
    }
   ],
   "source": [
    "# 4. Most common company\n",
    "print(\"\\n=== Most Common Company ===\")\n",
    "company_counts = users_df[users_df['company'].notna()]['company'].value_counts()\n",
    "print(f\"Most common company: {company_counts.index[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Most Popular Programming Language ===\n",
      "Most popular language: JavaScript\n"
     ]
    }
   ],
   "source": [
    "# 5. Most popular programming language (overall)\n",
    "print(\"\\n=== Most Popular Programming Language ===\")\n",
    "lang_counts = repos_df[repos_df['language'].notna()]['language'].value_counts()\n",
    "print(f\"Most popular language: {lang_counts.index[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Second Most Popular Language (Post-2020 Users) ===\n",
      "Second most popular language (post-2020): Python\n"
     ]
    }
   ],
   "source": [
    "# 6. Second most popular language for users who joined after 2020\n",
    "print(\"\\n=== Second Most Popular Language (Post-2020 Users) ===\")\n",
    "users_df['created_at'] = pd.to_datetime(users_df['created_at'])\n",
    "recent_users = users_df[users_df['created_at'] > '2020-01-01']['login'].unique()\n",
    "recent_repos = repos_df[repos_df['login'].isin(recent_users)]\n",
    "recent_lang_counts = recent_repos[recent_repos['language'].notna()]['language'].value_counts()\n",
    "print(f\"Second most popular language (post-2020): {recent_lang_counts.index[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Language with Highest Average Stars ===\n",
      "Language with highest avg stars: Markdown\n"
     ]
    }
   ],
   "source": [
    "# 7. Language with highest average stars\n",
    "print(\"\\n=== Language with Highest Average Stars ===\")\n",
    "lang_stars = repos_df[repos_df['language'].notna()].groupby('language').agg({\n",
    "    'stargazers_count': ['count', 'mean']\n",
    "}).sort_values(('stargazers_count', 'mean'), ascending=False)\n",
    "# Filter languages with at least 5 repositories\n",
    "lang_stars = lang_stars[lang_stars[('stargazers_count', 'count')] >= 5]\n",
    "print(f\"Language with highest avg stars: {lang_stars.index[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Top 5 Users by Leader Strength ===\n",
      "Top leaders: codewithMUHILAN,Premalatha-success,aswintechguy,manikandanraji,jaganjavid\n",
      "\n",
      "=== Correlation Analysis ===\n",
      "Correlation between followers and public repos: 0.081\n"
     ]
    }
   ],
   "source": [
    "# 8. Leader strength calculation\n",
    "print(\"\\n=== Top 5 Users by Leader Strength ===\")\n",
    "users_df['leader_strength'] = users_df['followers'] / (1 + users_df['following'])\n",
    "top_leaders = users_df.nlargest(5, 'leader_strength')\n",
    "print(\"Top leaders:\", \",\".join(top_leaders['login'].tolist()))\n",
    "\n",
    "# 9. Correlation between followers and public repos\n",
    "print(\"\\n=== Correlation Analysis ===\")\n",
    "correlation = users_df['followers'].corr(users_df['public_repos'])\n",
    "print(f\"Correlation between followers and public repos: {correlation:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Followers per additional repo (slope): 0.285\n"
     ]
    }
   ],
   "source": [
    "# 10. Followers vs Repos regression\n",
    "from scipy import stats\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(users_df['public_repos'], users_df['followers'])\n",
    "print(f\"\\nFollowers per additional repo (slope): {slope:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Projects-Wiki correlation: 0.221\n"
     ]
    }
   ],
   "source": [
    "# 11. Projects and Wiki correlation - Fixed\n",
    "# Convert 'has_projects' and 'has_wiki' to numerical values, where 'true' becomes 1 and 'false' becomes -1\n",
    "repos_df['has_projects_num'] = repos_df['has_projects'].apply(lambda x: 1 if x == True else -1)\n",
    "repos_df['has_wiki_num'] = repos_df['has_wiki'].apply(lambda x: 1 if x == True else -1)\n",
    "\n",
    "# Calculate the correlation between the two columns\n",
    "projects_wiki_corr = repos_df['has_projects_num'].corr(repos_df['has_wiki_num'])\n",
    "print(f\"\\nProjects-Wiki correlation: {projects_wiki_corr:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hireable vs non-hireable following difference: 241.706\n"
     ]
    }
   ],
   "source": [
    "# 12. Hireable users following difference\n",
    "users_df['is_hireable'] = users_df['hireable'] == 'true'\n",
    "hireable_following_avg = users_df[users_df['is_hireable']]['following'].mean()\n",
    "non_hireable_following_avg = users_df[~users_df['is_hireable']]['following'].mean()\n",
    "following_diff = hireable_following_avg - non_hireable_following_avg\n",
    "print(f\"\\nHireable vs non-hireable following difference: {following_diff:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Followers per bio word (slope): -1.663\n"
     ]
    }
   ],
   "source": [
    "# 13. Some developers write long bios. Does that help them get more followers? What's the impact of the length of their bio (in Unicode words, split by whitespace) with followers? (Ignore people without bios)\n",
    "from scipy import stats\n",
    "\n",
    "# Calculate bio length based on word count (split by whitespace)\n",
    "users_df['bio_length'] = users_df['bio'].fillna('').apply(lambda x: len(x.split()))\n",
    "\n",
    "# Filter out users without bios\n",
    "bio_users = users_df[users_df['bio_length'] > 0]\n",
    "\n",
    "# Perform linear regression to find the relationship between bio length and followers\n",
    "bio_slope, bio_intercept, bio_r_value, bio_p_value, bio_std_err = stats.linregress(\n",
    "    bio_users['bio_length'], bio_users['followers']\n",
    ")\n",
    "\n",
    "# Print the slope, indicating the estimated increase in followers per additional word in the bio\n",
    "print(f\"\\nFollowers per bio word (slope): {bio_slope:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 weekend repository creators: aasim-syed,nk-gears,karuppiah7890,rajasegar,TestLeafPages\n"
     ]
    }
   ],
   "source": [
    "# 14. Weekend warriors - Fixed\n",
    "# Convert created_at to datetime and extract day of week\n",
    "repos_df['created_at'] = pd.to_datetime(repos_df['created_at'])\n",
    "repos_df['is_weekend'] = repos_df['created_at'].dt.dayofweek.isin([5, 6])  # 5=Sat, 6=Sun\n",
    "weekend_counts = repos_df[repos_df['is_weekend']].groupby('login').size().sort_values(ascending=False)\n",
    "top_5_weekend = weekend_counts.head(5)\n",
    "print(f\"\\nTop 5 weekend repository creators: {','.join(top_5_weekend.index)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Hireable vs non-hireable email sharing difference: 0.255\n"
     ]
    }
   ],
   "source": [
    "# 15. Hireable users email sharing\n",
    "hireable_email_rate = users_df[users_df['is_hireable']]['email'].notna().mean()\n",
    "non_hireable_email_rate = users_df[~users_df['is_hireable']]['email'].notna().mean()\n",
    "email_diff = hireable_email_rate - non_hireable_email_rate\n",
    "print(f\"\\n Hireable vs non-hireable email sharing difference: {email_diff:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Most common surname(s): S\n",
      "Number of users with most common surname: 19\n"
     ]
    }
   ],
   "source": [
    "# Define function to extract the last word as the surname if available\n",
    "def get_surname(name):\n",
    "    if pd.isna(name) or not isinstance(name, str):\n",
    "        return None\n",
    "    # Split name by whitespace and get the last word as surname\n",
    "    parts = name.strip().split(' ')\n",
    "    return parts[-1] if len(parts) > 1 else None\n",
    "\n",
    "# Apply function to extract surname\n",
    "users_df['surname'] = users_df['name'].apply(get_surname)\n",
    "\n",
    "# Filter out None values and get the counts of each surname\n",
    "surname_counts = users_df['surname'].dropna().value_counts()\n",
    "\n",
    "# Find the highest count\n",
    "max_count = surname_counts.max()\n",
    "\n",
    "# Identify surnames that have this max count (i.e., most common surnames)\n",
    "most_common_surnames = surname_counts[surname_counts == max_count].index.tolist()\n",
    "\n",
    "# Sort alphabetically in case of ties\n",
    "most_common_surnames.sort()\n",
    "\n",
    "# Output results\n",
    "print(f\"\\nMost common surname(s): {','.join(most_common_surnames)}\")\n",
    "print(f\"Number of users with most common surname: {max_count}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
